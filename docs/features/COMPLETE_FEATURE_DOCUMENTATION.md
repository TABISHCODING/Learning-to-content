# ğŸ¯ Complete Feature Documentation - Learning-to-Content Python Backend

## ğŸ“‹ Table of Contents
1. [ğŸ¬ Complete Workflow Overview](#complete-workflow-overview)
2. [ğŸ”§ Core Features](#core-features)
3. [ğŸ—ï¸ Architecture](#architecture)
4. [ğŸ“Š Database Integration](#database-integration)
5. [ğŸµ Audio Generation](#audio-generation)
6. [ğŸ–¼ï¸ Image Generation](#image-generation)
7. [ğŸ¬ Video Assembly](#video-assembly)
8. [ğŸ’¾ Storage Management](#storage-management)
9. [ğŸ”„ Status Flow](#status-flow)
10. [ğŸš¨ Error Handling](#error-handling)

---

## ğŸ¬ Complete Workflow Overview

### **Exact n8n Workflow Replacement**
This Python backend provides **100% feature parity** with the original n8n workflow, implementing every single node and connection with identical functionality.

### **Complete Workflow Steps:**
```
1. ğŸ“¥ Webhook Receives Payload
   â†“
2. ğŸ§  Topic Extraction (Gemini API)
   â†“
3. ğŸ“ Script Generation (Gemini API)
   â†“
4. ğŸµ Audio Generation (Google TTS)
   â†“
5. ğŸ–¼ï¸ Image Generation (Cloudflare â†’ Together â†’ HuggingFace)
   â†“
6. ğŸ¬ Video Assembly (FFmpeg)
   â†“
7. ğŸ’¾ Google Drive Upload
   â†“
8. ğŸ“Š Database Update (Google Sheets)
   â†“
9. âœ… Completion Notification
```

---

## ğŸ”§ Core Features

### **1. Topic Extraction Engine**
- **API**: Gemini 1.5 Flash Latest
- **Function**: Extract structured topics from raw notes
- **Input**: Raw text notes from UI
- **Output**: Structured topic data with metadata
- **Status**: `Pending` â†’ `ScriptGenerated`

### **2. Script Generation Engine**
- **API**: Gemini 1.5 Flash Latest
- **Function**: Generate engaging scripts from topics
- **Input**: Extracted topic data
- **Output**: Formatted script with timing
- **Features**: 
  - Language-specific prompts (Hinglish support)
  - Tone customization (Friendly, Professional, etc.)
  - Platform optimization (YouTube Shorts, Instagram)

### **3. Audio Generation System**
- **API**: Google Cloud Text-to-Speech
- **Function**: Convert scripts to natural speech
- **Voice Mapping**:
  - `Male` â†’ `en-US-Journey-D` (Male voice)
  - `Female` â†’ `en-US-Journey-F` (Female voice)
- **Output**: High-quality MP3 audio files
- **Duration**: Optimized for 40-second videos

### **4. Image Generation Pipeline**
- **Primary**: Cloudflare Workers AI
- **Fallback 1**: Together AI
- **Fallback 2**: HuggingFace Inference API
- **Function**: Generate 4 contextual images per script
- **Features**:
  - Automatic prompt enhancement
  - Style consistency
  - Error resilience with multiple providers

### **5. Video Assembly Engine**
- **Tool**: FFmpeg
- **Function**: Combine audio + images into video
- **Specifications**:
  - Duration: 40 seconds total
  - Image display: 10 seconds each (4 images)
  - Format: MP4 with H.264 encoding
  - Resolution: 1080x1920 (vertical for mobile)

### **6. Storage Management**
- **Primary**: Google Drive integration
- **Function**: Organized file storage
- **Structure**:
  ```
  Google Drive/
  â”œâ”€â”€ Audio Files/
  â”œâ”€â”€ Generated Images/
  â””â”€â”€ Final Videos/
  ```

### **7. Database Integration**
- **Platform**: Google Sheets
- **Worksheets**:
  - `Topic Backlog`: Input topics and status
  - `Generated Content`: Final content metadata
  - `API_Usage`: Comprehensive API call logging
  - `ErrorLog`: Error tracking and debugging

---

## ğŸ—ï¸ Architecture

### **Backend Structure**
```
learning_to_content_python/backend/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ workflow_engine.py     # Main workflow orchestration
â”œâ”€â”€ api/
â”‚   â””â”€â”€ server.py              # Flask API server
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ gemini_service.py      # Gemini API integration
â”‚   â”œâ”€â”€ tts_service.py         # Google TTS integration
â”‚   â”œâ”€â”€ image_service.py       # Image generation services
â”‚   â”œâ”€â”€ video_service.py       # Video assembly service
â”‚   â”œâ”€â”€ drive_service.py       # Google Drive integration
â”‚   â””â”€â”€ sheets_service.py      # Google Sheets integration
â””â”€â”€ utils/
    â”œâ”€â”€ config.py              # Configuration management
    â”œâ”€â”€ logger.py              # Logging utilities
    â””â”€â”€ validators.py          # Input validation
```

### **Frontend Structure**
```
learning_to_content_python/frontend/
â””â”€â”€ streamlit_ui/
    â”œâ”€â”€ streamlit_app.py       # Main Streamlit application
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ topic_input.py     # Topic input form
    â”‚   â”œâ”€â”€ status_display.py  # Real-time status updates
    â”‚   â””â”€â”€ results_viewer.py  # Generated content viewer
    â””â”€â”€ utils/
        â””â”€â”€ ui_helpers.py      # UI utility functions
```

---

## ğŸ“Š Database Integration

### **Google Sheets Integration**
The system integrates with 4 specific worksheets:

#### **1. Topic Backlog Worksheet**
```python
# Columns:
- ID: Unique identifier
- Topic: Raw topic text
- Language: Content language
- Tone: Content tone
- Voice_Gender: Male/Female
- Platforms: Target platforms
- Status: Workflow status
- Created_At: Timestamp
- Updated_At: Last update
```

#### **2. Generated Content Worksheet**
```python
# Columns:
- ID: Links to Topic Backlog
- Script: Generated script text
- Audio_URL: Google Drive audio link
- Images_URLs: Google Drive image links (JSON array)
- Video_URL: Google Drive video link
- Duration: Content duration
- Generated_At: Completion timestamp
```

#### **3. API Usage Worksheet**
```python
# Columns:
- Timestamp: API call time
- Service: API service name (Gemini, TTS, etc.)
- Endpoint: Specific API endpoint
- Request_Size: Request data size
- Response_Size: Response data size
- Duration: API call duration
- Status: Success/Error
- Cost_Estimate: Estimated API cost
```

#### **4. ErrorLog Worksheet**
```python
# Columns:
- Timestamp: Error occurrence time
- Workflow_ID: Associated workflow ID
- Service: Service where error occurred
- Error_Type: Error classification
- Error_Message: Detailed error message
- Stack_Trace: Full stack trace
- Resolution_Status: Fixed/Pending/Investigating
```

---

## ğŸµ Audio Generation

### **Google Cloud Text-to-Speech Integration**
```python
def generate_audio(script_text, voice_gender, language="en-US"):
    """
    Generate high-quality audio from script text
    
    Args:
        script_text (str): The script to convert to speech
        voice_gender (str): "Male" or "Female"
        language (str): Language code (default: "en-US")
    
    Returns:
        str: Path to generated audio file
    """
    
    # Voice mapping
    voice_map = {
        "Male": "en-US-Journey-D",
        "Female": "en-US-Journey-F"
    }
    
    # TTS configuration
    synthesis_input = texttospeech.SynthesisInput(text=script_text)
    voice = texttospeech.VoiceSelectionParams(
        language_code=language,
        name=voice_map.get(voice_gender, "en-US-Journey-D"),
        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0,
        pitch=0.0
    )
    
    # Generate audio
    response = tts_client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )
    
    # Save and return file path
    audio_path = f"storage/generated_content/audio/{workflow_id}.mp3"
    with open(audio_path, "wb") as audio_file:
        audio_file.write(response.audio_content)
    
    return audio_path
```

### **Audio Features:**
- **Natural Voice Quality**: Journey voices for human-like speech
- **Customizable Parameters**: Speed, pitch, and tone control
- **Multiple Languages**: Support for various language codes
- **Optimized Duration**: Perfect timing for 40-second videos

---

## ğŸ–¼ï¸ Image Generation

### **Multi-Provider Image Generation System**
The system uses a robust fallback mechanism across three providers:

#### **1. Primary: Cloudflare Workers AI**
```python
def generate_image_cloudflare(prompt, workflow_id, image_index):
    """
    Generate image using Cloudflare Workers AI
    
    Args:
        prompt (str): Image generation prompt
        workflow_id (str): Unique workflow identifier
        image_index (int): Image sequence number (1-4)
    
    Returns:
        str: Path to generated image file
    """
    
    headers = {
        "Authorization": f"Bearer {CLOUDFLARE_API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "prompt": enhance_prompt(prompt),
        "num_steps": 20,
        "guidance": 7.5,
        "strength": 1.0
    }
    
    response = requests.post(
        f"https://api.cloudflare.com/client/v4/accounts/{CLOUDFLARE_ACCOUNT_ID}/ai/run/@cf/stabilityai/stable-diffusion-xl-base-1.0",
        headers=headers,
        json=payload
    )
    
    if response.status_code == 200:
        image_data = response.content
        image_path = f"storage/generated_content/images/{workflow_id}_image_{image_index}.png"
        
        with open(image_path, "wb") as image_file:
            image_file.write(image_data)
        
        return image_path
    else:
        raise Exception(f"Cloudflare API error: {response.status_code}")
```

#### **2. Fallback 1: Together AI**
```python
def generate_image_together(prompt, workflow_id, image_index):
    """
    Fallback image generation using Together AI
    """
    
    headers = {
        "Authorization": f"Bearer {TOGETHER_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "prompt": enhance_prompt(prompt),
        "width": 1024,
        "height": 1024,
        "steps": 20,
        "n": 1
    }
    
    response = requests.post(
        "https://api.together.xyz/inference",
        headers=headers,
        json=payload
    )
    
    # Process response and save image
    return process_together_response(response, workflow_id, image_index)
```

#### **3. Fallback 2: HuggingFace**
```python
def generate_image_huggingface(prompt, workflow_id, image_index):
    """
    Final fallback using HuggingFace Inference API
    """
    
    headers = {
        "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "inputs": enhance_prompt(prompt),
        "parameters": {
            "num_inference_steps": 20,
            "guidance_scale": 7.5
        }
    }
    
    response = requests.post(
        "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0",
        headers=headers,
        json=payload
    )
    
    # Process response and save image
    return process_huggingface_response(response, workflow_id, image_index)
```

### **Prompt Enhancement System**
```python
def enhance_prompt(base_prompt):
    """
    Enhance prompts for better image quality
    
    Args:
        base_prompt (str): Basic prompt from script
    
    Returns:
        str: Enhanced prompt with quality modifiers
    """
    
    quality_modifiers = [
        "high quality",
        "detailed",
        "professional",
        "clean background",
        "well-lit",
        "sharp focus",
        "vibrant colors"
    ]
    
    style_modifiers = [
        "modern",
        "clean",
        "minimalist",
        "professional photography style"
    ]
    
    enhanced_prompt = f"{base_prompt}, {', '.join(quality_modifiers)}, {', '.join(style_modifiers)}"
    
    return enhanced_prompt
```

---

## ğŸ¬ Video Assembly

### **FFmpeg Video Creation**
```python
def create_video(audio_path, image_paths, output_path, duration=40):
    """
    Create video by combining audio and images using FFmpeg
    
    Args:
        audio_path (str): Path to audio file
        image_paths (list): List of 4 image file paths
        output_path (str): Output video file path
        duration (int): Total video duration in seconds
    
    Returns:
        str: Path to created video file
    """
    
    # Calculate timing (10 seconds per image for 4 images = 40 seconds)
    image_duration = duration / len(image_paths)  # 10 seconds each
    
    # Create temporary file list for FFmpeg
    temp_list_path = f"temp_images_{workflow_id}.txt"
    
    with open(temp_list_path, "w") as f:
        for image_path in image_paths:
            f.write(f"file '{image_path}'\n")
            f.write(f"duration {image_duration}\n")
    
    # FFmpeg command to create video
    ffmpeg_cmd = [
        "ffmpeg",
        "-f", "concat",
        "-safe", "0",
        "-i", temp_list_path,
        "-i", audio_path,
        "-c:v", "libx264",
        "-c:a", "aac",
        "-pix_fmt", "yuv420p",
        "-vf", "scale=1080:1920,fps=30",  # Vertical format for mobile
        "-shortest",  # Match shortest stream (audio)
        "-y",  # Overwrite output file
        output_path
    ]
    
    # Execute FFmpeg command
    result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        # Clean up temporary files
        os.remove(temp_list_path)
        return output_path
    else:
        raise Exception(f"FFmpeg error: {result.stderr}")
```

### **Video Specifications:**
- **Resolution**: 1080x1920 (9:16 aspect ratio for mobile)
- **Frame Rate**: 30 FPS
- **Video Codec**: H.264 (libx264)
- **Audio Codec**: AAC
- **Duration**: 40 seconds total
- **Image Timing**: 10 seconds per image (4 images)
- **Audio Sync**: Perfect synchronization with visuals

---

## ğŸ’¾ Storage Management

### **Google Drive Integration**
```python
def upload_to_drive(file_path, folder_id, file_name):
    """
    Upload file to specific Google Drive folder
    
    Args:
        file_path (str): Local file path
        folder_id (str): Google Drive folder ID
        file_name (str): Name for uploaded file
    
    Returns:
        str: Google Drive file URL
    """
    
    # Initialize Drive service
    drive_service = build('drive', 'v3', credentials=drive_credentials)
    
    # File metadata
    file_metadata = {
        'name': file_name,
        'parents': [folder_id]
    }
    
    # Upload file
    media = MediaFileUpload(file_path, resumable=True)
    
    file = drive_service.files().create(
        body=file_metadata,
        media_body=media,
        fields='id,webViewLink,webContentLink'
    ).execute()
    
    # Make file publicly accessible
    drive_service.permissions().create(
        fileId=file.get('id'),
        body={'role': 'reader', 'type': 'anyone'}
    ).execute()
    
    return file.get('webViewLink')
```

### **Storage Organization:**
```
Google Drive Structure:
â”œâ”€â”€ Audio Files/
â”‚   â””â”€â”€ {workflow_id}.mp3
â”œâ”€â”€ Generated Images/
â”‚   â”œâ”€â”€ {workflow_id}_image_1.png
â”‚   â”œâ”€â”€ {workflow_id}_image_2.png
â”‚   â”œâ”€â”€ {workflow_id}_image_3.png
â”‚   â””â”€â”€ {workflow_id}_image_4.png
â””â”€â”€ Final Videos/
    â””â”€â”€ {workflow_id}_final_video.mp4
```

---

## ğŸ”„ Status Flow

### **Complete Status Workflow**
```python
# Status progression through workflow
STATUS_FLOW = {
    "Pending": "Initial state when workflow starts",
    "ScriptGenerated": "After topic extraction and script generation",
    "AudioGenerated": "After TTS audio creation",
    "ImagesGenerated": "After all 4 images are created",
    "VideoGenerated": "After video assembly completion",
    "Completed": "Final state with all assets uploaded"
}
```

### **Real-time Status Updates**
```python
def update_workflow_status(workflow_id, new_status, details=None):
    """
    Update workflow status in database and UI
    
    Args:
        workflow_id (str): Unique workflow identifier
        new_status (str): New status from STATUS_FLOW
        details (dict): Additional status details
    """
    
    # Update Google Sheets
    sheets_service.update_cell(
        GOOGLE_SHEET_ID,
        "Topic Backlog",
        f"G{row_number}",  # Status column
        new_status
    )
    
    # Update timestamp
    sheets_service.update_cell(
        GOOGLE_SHEET_ID,
        "Topic Backlog", 
        f"I{row_number}",  # Updated_At column
        datetime.now().isoformat()
    )
    
    # Log status change
    logger.info(f"Workflow {workflow_id} status updated: {new_status}")
    
    # Emit real-time update to UI (if using WebSocket)
    if websocket_enabled:
        emit_status_update(workflow_id, new_status, details)
```

---

## ğŸš¨ Error Handling

### **Comprehensive Error Management**
```python
def handle_workflow_error(workflow_id, service, error, context=None):
    """
    Comprehensive error handling and logging
    
    Args:
        workflow_id (str): Workflow identifier
        service (str): Service where error occurred
        error (Exception): The error object
        context (dict): Additional context information
    """
    
    # Create error record
    error_record = {
        "timestamp": datetime.now().isoformat(),
        "workflow_id": workflow_id,
        "service": service,
        "error_type": type(error).__name__,
        "error_message": str(error),
        "stack_trace": traceback.format_exc(),
        "context": json.dumps(context) if context else "",
        "resolution_status": "Pending"
    }
    
    # Log to ErrorLog worksheet
    sheets_service.append_row(
        GOOGLE_SHEET_ID,
        "ErrorLog",
        list(error_record.values())
    )
    
    # Update workflow status to error state
    update_workflow_status(workflow_id, "Error", {
        "error_type": error_record["error_type"],
        "error_message": error_record["error_message"]
    })
    
    # Send notification (if configured)
    if notification_enabled:
        send_error_notification(workflow_id, error_record)
    
    # Log to application logs
    logger.error(f"Workflow {workflow_id} error in {service}: {error}")
```

### **Error Recovery Mechanisms**
```python
def retry_with_backoff(func, max_retries=3, backoff_factor=2):
    """
    Retry function with exponential backoff
    
    Args:
        func: Function to retry
        max_retries: Maximum number of retry attempts
        backoff_factor: Backoff multiplier
    
    Returns:
        Function result or raises final exception
    """
    
    for attempt in range(max_retries + 1):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries:
                raise e
            
            wait_time = backoff_factor ** attempt
            logger.warning(f"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}")
            time.sleep(wait_time)
```

---

## ğŸ¯ Complete Feature Summary

### **âœ… 100% Feature Parity Achieved**

| Feature | n8n Implementation | Python Implementation | Status |
|---------|-------------------|----------------------|---------|
| Topic Extraction | Gemini API node | `gemini_service.py` | âœ… Complete |
| Script Generation | Gemini API node | `gemini_service.py` | âœ… Complete |
| Audio Generation | Google TTS node | `tts_service.py` | âœ… Complete |
| Image Generation | Multiple API nodes | `image_service.py` | âœ… Complete |
| Video Assembly | FFmpeg node | `video_service.py` | âœ… Complete |
| Google Sheets | Sheets API nodes | `sheets_service.py` | âœ… Complete |
| Google Drive | Drive API nodes | `drive_service.py` | âœ… Complete |
| Status Flow | Workflow logic | `workflow_engine.py` | âœ… Complete |
| Error Handling | Error nodes | Comprehensive system | âœ… Complete |
| Webhook Endpoint | Webhook node | Flask API endpoint | âœ… Complete |

### **ğŸš€ Enhanced Features Beyond n8n**
- **Better Error Recovery**: Exponential backoff and retry mechanisms
- **Real-time UI Updates**: Live status updates in Streamlit interface
- **Comprehensive Logging**: Detailed API usage and error tracking
- **Multi-provider Fallbacks**: Robust image generation with 3 providers
- **Optimized Performance**: Faster execution with Python optimizations

---

**ğŸ¯ This Python backend provides complete feature parity with the original n8n workflow while adding enhanced reliability, better error handling, and improved user experience through the Streamlit interface.**
